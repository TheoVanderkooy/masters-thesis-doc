%======================================================================
\chapter{Introduction}
%======================================================================


Buffer management is a critical task in database systems.  A database system's buffer manager controls main memory with the task to limit the number of buffers in use so that they fit in the main memory of the machine running the database system.

For most database systems, e.g., PostgreSQL, the buffer manager controls the memory directly.  This means that when requests exceed the available space, the buffer manager has to pick a buffer to empty by returning its contents to secondary storage.  The critical decision that the buffer manager must make is what block to evict from the buffer (memory) pool when a new block is requested.  For example, PostgreSQL uses the popular Clock algorithm~\cite{pg_buf_readme} to make eviction decisions. % \cite{pg_buf_internals}

The eviction decisions that a buffer manager makes is analogous to cache management/eviction policies that apply generally to all forms of caching, e.g. web caches and CPU caches.  Since reading from secondary storage is significantly slower than reading from memory, it would be greatly beneficial to keep as much data in memory as possible.  Since memory is still much more expensive than common forms of secondary storage, systems are typically forced to choose what to keep in memory for faster access within the available limit on the server.  However, the objective is the same as for buffer pool management: how to minimize the number of storage accesses (I/O) by increasing the hit rate of data blocks in memory and improve overall system performance.
A key challenge in increasing buffer pool hit rates is to have low running times for the policy that manages the buffer pool through low-latency eviction decisions.

An \textit{optimal} eviction strategy requires knowledge about \textit{future} accesses, making it impossible to implement in a real system. As such, real systems tend to use simple heuristics with low latency computation such as Clock~\cite{gclock} or Least-Recently-Used (LRU).

The optimal policy can be leveraged in the form of \gls{pbm}, where the buffer manager \textit{predicts} future accesses to inform cache eviction decisions and tries to mimic the optimal caching policy. \citet{pbm} use such a strategy, exploiting the structure of sequential database scans to estimate the next access time of data in the cache. Their approach uses a priority-queue based strategy and was originally implemented in a closed source system called Actian Vector. We describe this approach in more detail in Section~\ref{sec:pbm-pq_summary}.

\textbf{Contributions}: In this paper, we propose an alternate approach to predictive buffer management using sampling that is simpler, more flexible and extensible, and generally uses more up-to-date estimates. We show that our sampling-based approach can perform better than the prior priority-queue based approach for some workloads. Moreover, we take advantage of our extensible design to predict index scans to expand the set of workloads on which predictive buffer management can be used. We provide an open-source implementation in PostgreSQL of both our approach and the prior approach \cite{pbm} while describing the implementation aspects of the work.
